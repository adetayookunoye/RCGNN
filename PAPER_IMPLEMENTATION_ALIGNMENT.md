# ğŸ“‹ Paper Requirements vs Implementation: Side-by-Side Comparison

**Purpose**: Quick visual reference showing what the paper requires vs what code does.

**Updated**: October 27, 2025

---

## Abstract & Introduction Claims

| Paper Claim | Implementation Status | Evidence | Gap |
|---|---|---|---|
| Compound corruptions: noise, missingness, bias/drift | âœ… IMPLEMENTED | `recon.py`: Eq. 1 decomposition | None |
| Tri-latent encoder separates Z_S, Z_N, Z_B | âœ… IMPLEMENTED | `rcgnn.py` lines 8-46 | None |
| Structure-level invariance across regimes | âœ… IMPLEMENTED | `invariance.py` + integrated in `train_rcgnn.py` | None |
| Target: 60% variance reduction | âš ï¸ CODED, NOT TESTED | Code ready; metrics exist | No validation experiment |
| Maintain SHD under corruption | âš ï¸ CODED, NOT TESTED | Training runs; no benchmark | No corruption test |

---

## Problem Formulation (Section 3)

### Definition 1: Compound Corruption Process
```
Paper: X(t) = B^(e) âŠ™ S(t) + b^(e) + Îµ^(e)(t)
Code:  src/models/recon.py line ~80-83
âœ… MATCH: All three components modeled
```

### Assumption 1: Partial Invariance
```
Paper: G* and mechanisms invariant; corruption patterns vary
Code:  Enforced via structure-level invariance loss
âœ… MATCH: IRMStructureInvariance implements this
```

### Learning Objective
```
Paper: min SHD + Î»Â·Var[A^(e)]
Code:  compute_total_loss() in optim.py
âœ… MATCH: Both terms in total loss
```

---

## RC-GNN Framework (Section 4)

### 4.1 Tri-Latent Encoding

**Paper Requirements** (Eq. 3-5):
```
Z_S = E_S(Imputer(X, M), e)      # Signal  
Z_N = E_N(Imputer(X, M), e)      # Noise context
Z_B = E_B(XÌ„_e, e)                # Bias/drift
```

**Implementation Status**:

| Component | Paper | Code | Status | Gap |
|-----------|-------|------|--------|-----|
| Signal encoder E_S | âœ… | `rcgnn.py:13-17` | âœ… | None |
| Noise encoder E_N | âœ… | `rcgnn.py:19-23` | âœ… | None |
| Bias encoder E_B | âœ… | `rcgnn.py:25-29` | âœ… | None |
| **Imputer(X,M)** | âœ… GRU-D spec | Partial | âš ï¸ | **No masking-aware imputation; no uncertainty** |
| Environment index e | âœ… | `config: n_envs` | âœ… | None |

**Gap Details**: Paper specifies "Masking-aware imputer (GRU-D or Transformer)" but code skips this step:
```python
# Current (WRONG):
z_s = E_S(x)  # x is raw, possibly with NaN

# Should be:
x_imputed, uncertainty = Imputer(x, M)
z_s = E_S(x_imputed)  # Clean input
```

**Impact**: Not critical for initial training, but reduces missingness handling fidelity.

---

### 4.2 Causal Structure Learning

**Paper Requirements** (Eq. 6-7):
```
A = Ïƒ(GNN_A(Ï†(Z_S)))                    # Adjacency
Ä¥(A) = trace(exp(AâŠ™A)) - d = 0        # Acyclicity
Åœ_j(t) = g_j(Î£_k A_kj Ïˆ_{kâ†’j}(Z_{S,k}))  # Mechanisms
```

| Requirement | Paper | Code | Status | Gap |
|---|---|---|---|---|
| Adjacency via GNN | âœ… | `structure.py` | âœ… | None |
| Acyclicity penalty | âœ… | `optim.py:42-79` | âœ… | None |
| Per-node mechanisms g_j | âœ… | `mechanisms.py` | âœ… | None |
| **Edge functions Ïˆ_kâ†’j** | âœ… Edge-specific | Shared weights | âš ï¸ | **Using shared MLP for all edges, not edge-specific** |

**Gap Details**: Paper specifies edge-specific transformation networks but code likely uses shared parameters:
```python
# Current (ACCEPTABLE):
Ïˆ = MLP()  # Single network for all edges
for k, j:
    h = Ïˆ(Z_S_k)

# Should be (for full fidelity):
Ïˆ = {(k,j): MLP_kj() for k,j}  # dÃ—d networks
for k, j:
    h = Ïˆ[k,j](Z_S_k)
```

**Impact**: Reduces model expressiveness but not critical; training still works.

---

### 4.3 Corruption-Aware Reconstruction

**Paper Equation** (Eq. 8):
```
XÌ‚(t) = BÌ‚^(e)(Z_B)âŠ™Åœ(t) + bÌ‚^(e)(Z_B) + Î·(Z_N, e)
```

| Component | Paper | Code | Status | Gap |
|---|---|---|---|---|
| Multiplicative bias BÌ‚^(e) | âœ… | `recon.py` | âœ… | None |
| Additive bias bÌ‚^(e) | âœ… | `recon.py` | âœ… | None |
| Noise generation Î· | âœ… | `recon.py` | âœ… | None |
| Signal reconstruction Åœ | âœ… | `rcgnn.py` | âœ… | None |

**Status**: âœ… COMPLETE

---

## Training Objective (Section 5)

**Paper Equation** (Eq. 9):
```
L(Î¸) = L_recon + Î»_acyÂ·h(A) + Î»_invÂ·L_inv + Î»_disÂ·L_disent + Î»_sparseÂ·â€–Aâ€–â‚ + Î»_mechÂ·L_mech
```

| Loss Term | Paper | Code | Status | Gap |
|---|---|---|---|---|
| L_recon | âœ… Eq. 10 | `optim.py:92` | âœ… | None |
| Î»_acyÂ·h(A) | âœ… | `optim.py:42` | âœ… | None |
| Î»_invÂ·L_inv | âœ… Eq. 11-12 | `invariance.py` + train loop | âœ… | None |
| Î»_disÂ·L_disent | âœ… Eq. 13 | `optim.py:115` | âœ… | None (uses correlation, not HSIC/MINE) |
| Î»_sparseÂ·â€–Aâ€–â‚ | âœ… | `optim.py:24` | âœ… | None |
| **Î»_mechÂ·L_mech** | âœ… Specified | Not found | âŒ | **MISSING: Mechanism fitting loss** |

**Gap Details**: Paper specifies mechanism fitting loss but not implemented:
```python
# Missing:
L_mech = MSE(S_true, S_predicted)
L_total += lambda_mech * L_mech
```

**Impact**: Can train without it (reconstruction acts as proxy), but paper requires it.

---

### 5.1 Structure-Level Invariance

**Paper Specifies** (Eq. 11-12):
```
L_inv^var = Var_{eâˆˆE}[A^(e)]        # Variance penalty
L_inv^IRM = Î£_e â€–âˆ‡_Ï‰ R_e(Ï‰âŠ™A^(e))â€–Â²  # IRM-inspired
```

| Approach | Paper | Code | Status |
|---|---|---|---|
| Variance penalty | âœ… | `invariance.py` | âœ… |
| IRM penalty | âœ… | `invariance.py` | âœ… |
| Multi-environment support | âœ… | config: `n_envs` | âœ… |

**Status**: âœ… COMPLETE

---

### 5.2 Disentanglement Loss

**Paper Specifies** (Eq. 13):
```
L_disent = HSIC(Z_S, Z_N) + HSIC(Z_S, Z_B) + MINE(Z_N, Z_B)
```

| Metric | Paper | Code | Status | Gap |
|---|---|---|---|---|
| HSIC | âœ… Specified | Correlation used | âš ï¸ | Simpler metric; works but not full fidelity |
| MINE | âœ… Specified | Correlation used | âš ï¸ | Simpler metric; works but not full fidelity |

**Status**: âœ… ACCEPTABLE (correlation is weaker but functional)

---

## Theoretical Analysis (Section 6)

### Proposition 1: Identifiability

**Paper Claims**: Graph G* identifiable from P(X|e) under Partial Invariance

| Requirement | Status | Evidence | Gap |
|---|---|---|---|
| Proof sketch provided | âœ… | Paper includes | N/A |
| **Empirical validation** | âŒ | Not done | **CRITICAL: No synthetic test** |

**Gap**: Paper makes theoretical claim but no experiment validates it.

### Proposition 2: Stability Bound

**Paper Claims**: Var[A^(e) - A^(e')] â‰¤ 2/Î»_inv Â· E[L_recon + L_disent]

| Requirement | Status | Evidence | Gap |
|---|---|---|---|
| Formula provided | âœ… | Paper Eq. 12 | N/A |
| **Empirical verification** | âŒ | Not done | **CRITICAL: No variance measurement** |

**Gap**: Paper provides bound but no experiment verifies it holds.

---

## Experiments (Section 7)

### H1: Structural Accuracy

**Paper Claim**: "RC-GNN maintains SHD within 15% of oracle under 40â€“60% missingness where baselines degrade >40%"

| Requirement | Status | Evidence | Gap |
|---|---|---|---|
| Test datasets | âŒ | Not generated | **CRITICAL** |
| RC-GNN runs | âœ… | Code exists | Can execute |
| Baselines | âœ… | `run_baselines.py` exists | Can execute |
| **Evaluation** | âŒ | Not done | **CRITICAL: No comparison results** |

### H2: Stability

**Paper Claim**: "Invariance loss reduces variance >60% compared to ablated versions"

| Requirement | Status | Evidence | Gap |
|---|---|---|---|
| Stability metrics | âŒ | Not implemented | **CRITICAL** |
| Multi-env training | âœ… | Code ready | Can execute |
| Variance measurement | âŒ | No function | **CRITICAL** |
| **Comparison results** | âŒ | Not done | **CRITICAL** |

### H3: Expert Agreement

**Paper Claim**: "RC-GNN identifies policy-relevant pathways with >80% expert agreement"

| Requirement | Status | Evidence | Gap |
|---|---|---|---|
| Learned graphs | âœ… | Can extract | Can execute |
| Expert panel | âš ï¸ | Not identified | **Need domain expert or literature** |
| Scoring rubric | âŒ | Not defined | Need to create |
| **Validation** | âŒ | Not done | **CRITICAL** |

---

## Evaluation Metrics (Section 7.3)

### Structural Accuracy Metrics
| Metric | Paper | Code | Status |
|---|---|---|---|
| SHD | âœ… | `metrics.py` | âœ… |
| Precision | âœ… | `metrics.py` | âœ… |
| Recall | âœ… | `metrics.py` | âœ… |
| F1 | âœ… | `metrics.py` | âœ… |
| Orientation Accuracy | âœ… | `metrics.py` | âœ… |

### **Stability Metrics (NEW - Paper Specific)**
| Metric | Paper | Code | Status | Impact |
|---|---|---|---|---|
| **Adjacency Variance** | âœ… Eq. 11 | âŒ Missing | ğŸ”´ CRITICAL | Can't validate H2 |
| **Edge-set Jaccard** | âœ… | âŒ Missing | ğŸ”´ CRITICAL | Can't measure consistency |
| **Policy Consistency** | âœ… | âŒ Missing | ğŸ”´ CRITICAL | Can't validate H3 |

### Practical Utility Metrics
| Metric | Paper | Code | Status |
|---|---|---|---|
| Expert Agreement | âœ… | âŒ Need framework | ğŸ”´ Not implemented |
| Decision Reliability | âœ… | âŒ | Not measured |
| Robustness Curves | âœ… | âš ï¸ Partial | Partially implemented |

---

## Baselines & Ablations (Section 7.3)

### Baselines
| Method | Paper | Code | Status |
|---|---|---|---|
| NOTEARS | âœ… | `run_baselines.py` | âœ… Can run |
| DCDI | âœ… | `run_baselines.py` | âœ… Can run |
| DECI | âœ… | `run_baselines.py` | âœ… Can run |
| MissDAG | âœ… | âš ï¸ | Need integration |
| Robust variants | âœ… | âš ï¸ | Need implementation |

### Ablations
| Ablation | Paper | Code | Status |
|---|---|---|---|
| RC-GNN without invariance | âœ… | âŒ Not configured | Can create config |
| RC-GNN without disentanglement | âœ… | âŒ Not configured | Can create config |
| RC-GNN without corruption modeling | âœ… | âŒ Not configured | Can create config |

---

## Summary: Implementation Coverage

### âœ… COMPLETE (Ready to Use)
- Tri-latent encoder architecture
- Structure learning with acyclicity
- Reconstruction with corruption modeling
- All 6 loss components
- Multi-environment support
- Training loop with checkpointing
- Standard evaluation metrics (SHD, F1)

### âš ï¸ PARTIAL (Functional but Incomplete Fidelity)
- Disentanglement loss (uses correlation, not HSIC/MINE)
- Edge transformation (shared weights, not edge-specific)
- Imputer (no masking-awareness, no uncertainty)

### âŒ MISSING (Blocking Publication)
- Stability metrics (adjacency_variance, edge_set_jaccard, policy_consistency)
- Mechanism fitting loss
- H1/H2/H3 validation experiments
- Baseline comparisons
- Ablation studies
- GRU-D masking-aware imputation (nice-to-have)

---

## Effort to Close All Gaps

| Gap | Type | Effort | Timeline |
|-----|------|--------|----------|
| Stability metrics | Implementation | 2-4 hours | Week 1 |
| Synthetic benchmarks | Implementation | 6-8 hours | Week 1 |
| GRU-D imputer | Implementation | 8-12 hours | Week 1 |
| H1/H2/H3 experiments | Execution | 20 hours | Week 3 |
| Baseline comparisons | Execution | 6 hours | Week 4 |
| Results writing | Analysis | 8-10 hours | Week 4 |
| **TOTAL** | | **60 hours** | **4 weeks** |

---

## Bottom Line: Paper Alignment Score

**Current**: 75% code complete, 10% experimentally validated  
**After Week 1**: 85% code complete, 10% validated  
**After Week 2**: 85% code complete, 30% validated (theory)  
**After Week 3**: 85% code complete, 90% validated (H1/H2/H3)  
**After Week 4**: 90% code complete, 100% validated (ready for submission)

**Path to Publication**: CLEAR âœ…

